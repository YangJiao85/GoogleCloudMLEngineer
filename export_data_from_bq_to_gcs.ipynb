{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting data from BigQuery to Google Cloud Storage\n",
    "\n",
    "In this notebook, we export BigQuery data to GCS so that we can reuse our Keras model that was developed on CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q google-cloud-bigquery==1.25.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please ignore any incompatibility warnings and errors.\n",
    "**Restart** the kernel to use updated packages. (On the Notebook menu, select Kernel > Restart Kernel > Restart).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary tensorflow library and printing the TF version.\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensorflow version: \",tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following cell as necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change with your own bucket and project below:\n",
    "BUCKET =  \"######\"\n",
    "PROJECT = \"######\"\n",
    "\n",
    "OUTDIR = \"gs://{bucket}/taxifare/data\".format(bucket=BUCKET)\n",
    "\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['OUTDIR'] = OUTDIR\n",
    "os.environ['PROJECT'] = PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BigQuery tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven not already created a BigQuery dataset for our data, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "bq = bigquery.Client(project = PROJECT)\n",
    "dataset = bigquery.Dataset(bq.dataset(\"taxifare\"))\n",
    "\n",
    "try:\n",
    "    bq.create_dataset(dataset)\n",
    "    print(\"Dataset created\")\n",
    "except:\n",
    "    print(\"Dataset already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a table with 1 million examples.\n",
    "\n",
    "Note that the order of columns is exactly what was in our CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 3/3 [00:00<00:00, 1442.50query/s]                        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE TABLE taxifare.feateng_training_data AS\n",
    "\n",
    "SELECT\n",
    "    (tolls_amount + fare_amount) AS fare_amount,\n",
    "    pickup_datetime,\n",
    "    pickup_longitude AS pickuplon,\n",
    "    pickup_latitude AS pickuplat,\n",
    "    dropoff_longitude AS dropofflon,\n",
    "    dropoff_latitude AS dropofflat,\n",
    "    passenger_count*1.0 AS passengers,\n",
    "    'unused' AS key\n",
    "FROM `nyc-tlc.yellow.trips`\n",
    "WHERE ABS(MOD(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING)), 1000)) = 1\n",
    "AND\n",
    "    trip_distance > 0\n",
    "    AND fare_amount >= 2.5\n",
    "    AND pickup_longitude > -78\n",
    "    AND pickup_longitude < -70\n",
    "    AND dropoff_longitude > -78\n",
    "    AND dropoff_longitude < -70\n",
    "    AND pickup_latitude > 37\n",
    "    AND pickup_latitude < 45\n",
    "    AND dropoff_latitude > 37\n",
    "    AND dropoff_latitude < 45\n",
    "    AND passenger_count > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the validation dataset be 1/10 the size of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 3/3 [00:00<00:00, 1591.16query/s]                        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE TABLE taxifare.feateng_valid_data AS\n",
    "\n",
    "SELECT\n",
    "    (tolls_amount + fare_amount) AS fare_amount,\n",
    "    pickup_datetime,\n",
    "    pickup_longitude AS pickuplon,\n",
    "    pickup_latitude AS pickuplat,\n",
    "    dropoff_longitude AS dropofflon,\n",
    "    dropoff_latitude AS dropofflat,\n",
    "    passenger_count*1.0 AS passengers,\n",
    "    'unused' AS key\n",
    "FROM `nyc-tlc.yellow.trips`\n",
    "WHERE ABS(MOD(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING)), 10000)) = 2\n",
    "AND\n",
    "    trip_distance > 0\n",
    "    AND fare_amount >= 2.5\n",
    "    AND pickup_longitude > -78\n",
    "    AND pickup_longitude < -70\n",
    "    AND dropoff_longitude > -78\n",
    "    AND dropoff_longitude < -70\n",
    "    AND pickup_latitude > 37\n",
    "    AND pickup_latitude < 45\n",
    "    AND dropoff_latitude > 37\n",
    "    AND dropoff_latitude < 45\n",
    "    AND passenger_count > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the tables as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting current contents of gs://######/taxifare/data\n",
      "Extracting training data to gs://######/taxifare/data\n",
      "Extracting validation data to gs://######/taxifare/data\n",
      "  88345235  2021-11-10T21:10:36Z  gs://######/taxifare/data/taxi-train-000000000000.csv\n",
      "   8725746  2021-11-10T21:10:47Z  gs://######/taxifare/data/taxi-valid-000000000000.csv\n",
      "TOTAL: 2 objects, 97070981 bytes (92.57 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r36476e3e483ed026_0000017d0bafe2d1_1 ... (24s) Current status: DONE   \n",
      "Waiting on bqjob_r577f75af817dd47f_0000017d0bb04ba2_1 ... (3s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"Deleting current contents of $OUTDIR\"\n",
    "gsutil -m -q rm -rf $OUTDIR\n",
    "\n",
    "echo \"Extracting training data to $OUTDIR\"\n",
    "bq --location=US extract \\\n",
    "   --destination_format CSV  \\\n",
    "   --field_delimiter \",\" --noprint_header \\\n",
    "   taxifare.feateng_training_data \\\n",
    "   $OUTDIR/taxi-train-*.csv\n",
    "\n",
    "echo \"Extracting validation data to $OUTDIR\"\n",
    "bq --location=US extract \\\n",
    "   --destination_format CSV  \\\n",
    "   --field_delimiter \",\" --noprint_header \\\n",
    "   taxifare.feateng_valid_data \\\n",
    "   $OUTDIR/taxi-valid-*.csv\n",
    "\n",
    "gsutil ls -l $OUTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.5,2012-11-24 18:06:45 UTC,-73.77674,40.645477,-73.993984,40.69777,2,unused\n",
      "20.83,2013-05-30 22:25:59 UTC,-74.001792,40.739539,-73.956885,40.746525,2,unused\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat gs://$BUCKET/taxifare/data/taxi-train-000000000000.csv | head -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m84",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m84"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
